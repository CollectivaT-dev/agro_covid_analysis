{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"abastiment.csv\", sep=\",\")\n",
    "\n",
    "dd = pd.read_csv(\"abastiment.csv\", sep=\",\")\n",
    "dd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    " \n",
    "#load a set of stop words\n",
    "from stop_words import get_stop_words\n",
    "stopwords = get_stop_words('catalan')\n",
    "\n",
    "#add new stopwords\n",
    "newStopWords = ['que','des', 'al', 'del', 'ho']\n",
    "stopwords.extend(newStopWords)\n",
    "\n",
    "#stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "    \n",
    "    ## remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    # remove only digits\n",
    "    #text=re.sub(\"(\\\\d)+\",\" \",text)\n",
    "\n",
    "    \n",
    "    #text=unidecode(text) ##if I do it I need to do it also in the stopwords\n",
    "    \n",
    "    return text\n",
    " \n",
    "\n",
    "dd['COM COMPRAR'].fillna('xx', inplace=True)\n",
    "dd['PRODUCTE(S)'].fillna('xx', inplace=True)\n",
    "dd['OBSERVACIONS'].fillna('xx', inplace=True)\n",
    "dd['MUNICIPI'].fillna('xx', inplace=True)\n",
    "\n",
    "\n",
    "dd['COM COMPRAR'] = dd['COM COMPRAR'].apply(lambda x:pre_process(x))\n",
    "dd['PRODUCTE(S)'] = dd['PRODUCTE(S)'].apply(lambda x:pre_process(x))\n",
    "dd['OBSERVACIONS'] = dd['OBSERVACIONS'].apply(lambda x:pre_process(x))\n",
    "dd['MUNICIPI'] = dd['MUNICIPI'].apply(lambda x:pre_process(x))\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the new  and old 'text' \n",
    "print(dd['COM COMPRAR'][1])\n",
    "print(data['COM COMPRAR'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each of the 3 mains text columns, create a list where the different elements are the different records  \n",
    "docs=dd['COM COMPRAR'].tolist()\n",
    "docs1=dd['PRODUCTE(S)'].tolist()\n",
    "docs2=dd['OBSERVACIONS'].tolist()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =' '\n",
    "\n",
    "testo=s.join(docs)\n",
    "testo1=s.join(docs1)\n",
    "testo2=s.join(docs2)\n",
    "\n",
    "#print(testo)\n",
    "\n",
    "text=[testo]   #uncomment to analyze COM COMPRAR\n",
    "#text=[testo1] #uncomment to analyze PRODUCTE(S)\n",
    "#text=[testo2] #uncomment to analyze OBSERVACIONS\n",
    "\n",
    "#print(text)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "\n",
    "#show the vocabulary ordered alphabetially (by key):\n",
    "sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Encode document\n",
    "vector = vectorizer.transform(text)  \n",
    "##NB: qui sopra sto contando quante volte appare ogni parola del vocabolario nel documento\n",
    "\n",
    "#-- Summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    get_top_n_words([\"I love Python\", \"Python is a language programming\", \"Hello world\", \"I love the world\"]) -> \n",
    "    [('python', 2),\n",
    "     ('world', 2),\n",
    "     ('love', 2),\n",
    "     ('hello', 1),\n",
    "     ('is', 1),\n",
    "     ('programming', 1),\n",
    "     ('the', 1),\n",
    "     ('language', 1)]\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(stop_words=stopwords).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "#print N first most common words\n",
    "common_words = get_top_n_words(text, 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- LISTS OF KEYWORDS en PRODUCTE(S):\n",
    "\n",
    "fruit=['fruita', 'fruites', 'fruits', 'figues', 'cireres', 'pomes', 'poma' , 'pera', 'peres', 'taronges',\\\n",
    "       'taronja','albercocs', 'albercoc', 'pruna', 'préssec', 'nectarina', 'anous',  'avellanes','ametlles',\\\n",
    "       'ametlla', 'maduixes'] \n",
    "#fruits are sec or silvestres; I let out: 'uva', 'avellana', 'frambuesa', 'llimona'\n",
    "\n",
    "\n",
    "    \n",
    "vegetables=['hortalisses', 'horta', 'hort','verdures', 'verdura', 'espinacs','espinac', 'calçots', 'patata',\\\n",
    "            'patates', 'ceba','col', 'cols', 'coliflors', 'coliflor','bròcolis','brocoli','broquil', 'carxofas','carxofa', \\\n",
    "            'carbasso', 'carbassa', 'enciams', 'enciam', 'bleda', 'pastanaga', 'porro','remolatxa', 'mongeta'\\\n",
    "            'cogombre', 'tomàquets', 'cistelles'] \n",
    "#I put also 'cistelles' because they say cistelles d'horta or cistelles ecologiques without saying any words of fruit or vegetables\n",
    "  \n",
    "    \n",
    "legumes=['llegums','faves', 'pesol', 'cigrons', 'llentia', 'verdina', 'cigró', 'moreu']\n",
    "\n",
    "meat=['carn', 'carnisseria', 'xai', 'xais','cabrit','cabrits','vedella', 'corder','botifarres', 'botifarra', \\\n",
    "      'bistecs','pollastre','pollastres','hamburgueses', 'porc', 'embotits', 'llom','llonganissa','fuets'\n",
    "      'somaies', 'xoriç', 'sobressada', 'entrecot' , 'filets', 'xurrasco'] #embutit appears as vegan, \n",
    "\n",
    "\n",
    "mushrooms=['bolets', 'bolet', 'xampinyó', 'setas']\n",
    "\n",
    "rice=['arròs', 'arroç', 'arrossos','arrosos']\n",
    "\n",
    "flour_cereals=['farines', 'farina','cereals', 'blats', 'blat']\n",
    "\n",
    "oil_olives_vinager=['oli', 'olis', 'oliva', 'olives', 'vinagre']\n",
    "\n",
    "eggs=['ous']\n",
    "dairies=['làctics','llet','formatge', 'formatges','mató', 'lletò', 'lletó', 'iogurt', 'iogurts', 'yogurt']\n",
    "\n",
    "herbs_spices=['espècies', 'aromàtiques', 'farigola', 'safrà']\n",
    "hygiene_medicines=['higiene','cosmètics','cosmètica', 'baño', 'jabón', 'sabó', 'sabons', 'champús', 'xampú',\n",
    "                  'medicinals', 'detergents', 'rentavaixelles', 'desengreixant']\n",
    "\n",
    "alchool=['vi','vins', 'vermut', 'cervesa', 'cerveses', 'caves', 'ratafia', 'licors','sidra', 'celler']\n",
    "\n",
    "\n",
    "fruit_veggies_products=['suc', 'sucs', 'melmelades', 'mel','mels', 'cremes', 'conserves',\\\n",
    "                        'confitures', 'germinats', 'mostassa', 'salsa', 'salses', 'allioli', \\\n",
    "                        'elaborats']\n",
    "\n",
    "drinks=['cafès', 'infusions', 'mate' , 'refresc', 'begudes', 'kombutxa', 'llets', 'té', 'kombutxes'] #do not use caffeina!\n",
    "\n",
    "flowers=['flors']\n",
    "  \n",
    "bread_pastries=['dolços','dolç', 'galetes', 'brioxeria' ,'brioixeria', 'pa', 'pan', 'fleca', 'forner',\\\n",
    "              'magdalenes', 'coca']\n",
    "pasta=[ 'pasta', 'pastes']\n",
    "\n",
    "others=['sucre', 'sucres', 'llaunes', 'espirulina', 'brou', 'flocs', 'llavors','concentrat', \\\n",
    "       'pinsos', 'pinso',  'planter', 'llenya', 'tintura',  'xocolata'] #llavors=semi; pinsos=mangimi, planter=piantine\n",
    "  \n",
    "eco_words=['ccpae', 'certificat', 'agroecològiques','agroecològica', 'agroecològic', \\\n",
    "           'biològics',  'certificada' , 'certificació',\\\n",
    "           'ecológics', 'ecológica','ecològiques', 'ecològics', 'ecològica', 'ecològic',\\\n",
    "           'ecologics','ecologica',  'eco']\n",
    "\n",
    "\n",
    "  \n",
    "#---- LISTS OF KEYWORDS en COM COMPRAR: ----------------------------------------------\n",
    "\n",
    "delivery_words=['domicili', 'casa',  'porta', 'cases'\\\n",
    "                'enviem', 'enviament', 'enviaments','envio', \\\n",
    "                'repartim', 'repartiment' , 'reparto' , 'repartirem', 'repartiments', 'reparteix', 'glovo'] \n",
    "# => hasDELIVERY=1  \n",
    "##NB: sometimes enviem is related to orders or locations (enviem ubicacio, enviem el llistat, etc..), \n",
    "## on the other side i do not include enviar and enviant that generally is related to emails and orders\n",
    "## Also the word casa sometimes can produce a wrong result\n",
    "\n",
    "mail_words=['correu', 'correo', 'mail', 'email', 'electrònica', 'electrònic', 'electronic', 'gmail'] \n",
    "##'@' is removed in the preprocessing \n",
    "# => hasMAIL=1  ##NB:do not include correus which they use it when they say by post\n",
    "\n",
    "web_words=['web', 'online', 'www', 'línia', 'internet', 'line', 'https', 'http'] \n",
    "# => hasWEB=1\n",
    "\n",
    "pickup_words=['recollir', 'recollida','recogida','punts', 'punt', 'trobada','presencial', 'presencialment',\\\n",
    "              'finca', 'camp', 'masia', 'magatzem', 'explotació', 'directa', \\\n",
    "              'entrega',  'entregues', 'entregar', 'distribuïm', 'botigues','carnisseries' ]  \n",
    "#=> hasPICKUPPOINT\n",
    "#NB: sometimes there are negations: \"No fem venda al detall ni a la finca.\" which i am not considering\n",
    "## I moved here entrega and related words because ofen they are used to say they deliver to a pick up point, \n",
    "## and when used for home delivery the word domicili always appears \n",
    "\n",
    "shop_words=['botiga', 'agrobotiga', 'celler', 'carnisseria', 'carnisseia'] \n",
    "#=> hasSHOP NB: sometimes botiga in reality is botiga on line\n",
    "\n",
    "market_words=['mercat', 'mercats'] \n",
    "## => hasMARKET\n",
    "\n",
    "phone_words=['telèfon', 'teléfono','teléfon','telefon','telefòn','telf','tfn', 'tel','telefònica',  \\\n",
    "             'telefonicament', 'trucar', 'trucant',  'tucar', 'trucan', 'trucada', 'mòbil'] \n",
    "# => hasPHONE=1\n",
    "\n",
    "orders_words=['comanda', 'comandes', 'reben', 'contactar'] \n",
    "## => acceptORDERS\n",
    "\n",
    "whatsapp_words=['wp','whatsapps','whatsapp','whatsap','whats','whataapp','what','whaap','wattsap',\\\n",
    "                'watsup', 'watssap','watshapp','watsapp', 'watsap', 'wassap', 'wasap']\n",
    "##=> hasWHATSAPP  NB:NEED TO BE FIXED\n",
    "\n",
    "\n",
    "socialnet_words=['xarxes', 'facebook', 'twitter','instagram', 'instragram']\n",
    "\n",
    "##'venta', 'venda' (it can be directa, a domicili, online)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def findWords(field, search):   \n",
    "    vectorizer.fit([field])\n",
    "    #print(field)\n",
    "    lst=list(vectorizer.vocabulary_.keys())\n",
    "    #print(lst)\n",
    "    \n",
    "    if any(word in set(lst) for word in search):\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#-- Creating binary variables describing buying options    \n",
    "dd['hasDELIVERY'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], delivery_words),axis=1)\n",
    "dd['hasPICKUP'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], pickup_words),axis=1)\n",
    "dd['hasSHOP'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], shop_words),axis=1)\n",
    "dd['hasWEB'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], web_words),axis=1)\n",
    "dd['hasPHONE'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], phone_words),axis=1)\n",
    "dd['hasMAIL'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], mail_words),axis=1)\n",
    "dd['hasWHATSAPP'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], whatsapp_words),axis=1)\n",
    "dd['hasMARKET'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], market_words),axis=1)\n",
    "dd['hasSOCIALNET'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], socialnet_words),axis=1)\n",
    "##dd['hasORDERS'] = dd.apply(lambda x: findWords(x['COM COMPRAR'], orders_words),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#pd.options.display.max_colwidth = 300\n",
    "#dd[['COM COMPRAR', 'hasDELIVERY', 'hasPICKUP', 'hasSHOP', 'hasMARKET','hasWEB', 'hasSOCIALNET', 'hasPHONE', 'hasWHATSAPP', 'hasMAIL']].tail(5)\n",
    "\n",
    "\n",
    "\n",
    "#-- Creating binary variables describing products sold\n",
    "dd['sellBREAD_PASTRIES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], bread_pastries),axis=1)\n",
    "dd['sellRICE'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], rice),axis=1)\n",
    "dd['sellMEAT'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], meat),axis=1)\n",
    "dd['sellFRUIT'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], fruit),axis=1)\n",
    "dd['sellVEGETABLES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], vegetables),axis=1)\n",
    "dd['sellLEGUMES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], legumes),axis=1)\n",
    "dd['sellDAIRIES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], dairies),axis=1)\n",
    "dd['sellEGGS'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], eggs),axis=1)\n",
    "dd['sellPASTA'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], pasta),axis=1)\n",
    "dd['sellFRUITVEG_PROD'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], fruit_veggies_products),axis=1)\n",
    "dd['sellALCHOOL'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], alchool),axis=1)\n",
    "dd['sellDRINKS'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], drinks),axis=1)\n",
    "dd['sellHERBS_SPICES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], herbs_spices),axis=1)\n",
    "dd['sellFLOWERS'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], flowers),axis=1)\n",
    "dd['sellMUSHROOM'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], mushrooms),axis=1)\n",
    "dd['sellFLOUR_CEREALS'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], flour_cereals),axis=1)\n",
    "dd['sellOIL_OLIVES'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], oil_olives_vinager),axis=1)\n",
    "dd['sellHYGIENE'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], hygiene_medicines),axis=1)\n",
    "dd['sellOTHER_PROD'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], others),axis=1)\n",
    "dd['isECO'] = dd.apply(lambda x: findWords(x['PRODUCTE(S)'], eco_words),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineVAR(column, field, search):   \n",
    "    #print(column)\n",
    "    vectorizer.fit([field])\n",
    "    #print(field)\n",
    "    lst=list(vectorizer.vocabulary_.keys())\n",
    "    #print(lst)\n",
    "    \n",
    "    if any(word in set(lst) for word in search):\n",
    "        return 1 \n",
    "    else:\n",
    "        return column\n",
    "\n",
    "    \n",
    "#--Cleaning a bit the web and social networks variables, by adding info from OBSERVACIONS field    \n",
    "dd['hasWEB'] =dd.apply(lambda x: refineVAR(x['hasWEB'],x['OBSERVACIONS'], web_words),axis=1)\n",
    "dd['hasSOCIALNET'] =dd.apply(lambda x: refineVAR(x['hasSOCIALNET'],x['OBSERVACIONS'], socialnet_words),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Checking the data:\n",
    "pd.options.display.max_colwidth = 500\n",
    "dd[['PRODUCTE(S)', 'sellBREAD_PASTRIES', 'sellRICE',\n",
    "       'sellMEAT', 'sellFRUIT', 'sellVEGETABLES', 'sellLEGUMES', 'sellDAIRIES',\n",
    "       'sellEGGS','sellPASTA', 'sellFRUITVEG_PROD', 'sellALCHOOL',\n",
    "       'sellDRINKS', 'sellHERBS_SPICES', 'sellFLOWERS', 'sellMUSHROOM',\n",
    "       'sellFLOUR_CEREALS', 'sellOIL_OLIVES', \n",
    "       'sellHYGIENE', 'sellOTHER_PROD',\n",
    "       'isECO']].head(5)\n",
    "\n",
    "#dd.columns\n",
    "\n",
    "#dd[['COM COMPRAR', 'hasDELIVERY', 'hasPICKUP', 'hasSHOP', 'hasMARKET','hasWEB', 'hasSOCIALNET', \n",
    "#    'hasPHONE', 'hasWHATSAPP', 'hasMAIL']].tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Creating variables about number of products sold:\n",
    "\n",
    "dd['N_PROD_PRINC']=dd['sellMEAT']+dd['sellFRUIT']+ dd['sellVEGETABLES']\n",
    "\n",
    "\n",
    "dd['N_PROD_OTROS']=dd['sellFLOWERS']+dd['sellRICE']+dd['sellPASTA']+dd['sellBREAD_PASTRIES']+ \\\n",
    "                    dd['sellFRUITVEG_PROD']+dd['sellOIL_OLIVES']+dd['sellHERBS_SPICES']+\\\n",
    "                    dd['sellLEGUMES']+dd['sellALCHOOL']+dd['sellDRINKS']+dd['sellEGGS']+ \\\n",
    "                    dd['sellDAIRIES']+dd['sellMUSHROOM']+ dd['sellFLOUR_CEREALS']+ dd['sellHYGIENE']+ \\\n",
    "                    dd['sellOTHER_PROD']\n",
    "\n",
    "dd['N_PROD_TOT']=dd['N_PROD_PRINC']+dd['N_PROD_OTROS']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing 'COM COMPRAR' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For this plot see pag: https://python-graph-gallery.com/13-percent-stacked-barplot/\n",
    "   \n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "dim=dd.shape[0]\n",
    "\n",
    "\n",
    "# Data\n",
    "r = [0,1,2,3]\n",
    "raw_data = {'yes': [sum(dd.hasDELIVERY), sum(dd.hasPICKUP), sum(dd.hasSHOP), sum(dd.hasMARKET)], \\\n",
    "            'no': [dim-sum(dd.hasDELIVERY), dim-sum(dd.hasPICKUP), dim-sum(dd.hasSHOP), dim-sum(dd.hasMARKET)]}\n",
    "df = pd.DataFrame(raw_data)\n",
    " \n",
    "df.head()\n",
    "\n",
    "df['suma']=df.yes+df.no\n",
    "\n",
    "df.head()\n",
    "\n",
    "# From raw value to percentage\n",
    "totals = [i+j for i,j in zip(df['yes'], df['no'])]\n",
    "greenBars = [i / j * 100 for i,j in zip(df['yes'], totals)]\n",
    "orangeBars = [i / j * 100 for i,j in zip(df['no'], totals)]\n",
    "#blueBars = [i / j * 100 for i,j in zip(df['blueBars'], totals)]\n",
    " \n",
    "\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7,7))\n",
    "barWidth = 0.85\n",
    "names = ('Delivery','Pick up','Shop','Market')\n",
    "# Create green Bars\n",
    "plt.bar(r, greenBars, color='#b5ffb9', edgecolor='white', width=barWidth, label='Yes')\n",
    "# Create orange Bars\n",
    "plt.bar(r, orangeBars, bottom=greenBars, color='mistyrose', edgecolor='white', width=barWidth, label='No')\n",
    "## Create blue Bars\n",
    "#plt.bar(r, blueBars, bottom=[i+j for i,j in zip(greenBars, orangeBars)], color='#a3acff', edgecolor='white', width=barWidth)\n",
    " \n",
    "# Custom x axis\n",
    "plt.xticks(r, names, rotation=30)\n",
    "plt.xlabel(\"\")\n",
    " \n",
    " \n",
    "# Add a legend\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Communication channels\n",
    "\n",
    "r = [0,1,2,3,4]\n",
    "raw_data = {'yes': [sum(dd.hasWEB), sum(dd.hasPHONE), sum(dd.hasMAIL), \\\n",
    "                    sum(dd.hasWHATSAPP), sum(dd.hasSOCIALNET)],\\\n",
    "            'no': [dim-sum(dd.hasWEB), dim-sum(dd.hasPHONE), dim-sum(dd.hasMAIL),\\\n",
    "                   dim-sum(dd.hasWHATSAPP), dim-sum(dd.hasSOCIALNET) ]}\n",
    "df = pd.DataFrame(raw_data)\n",
    " \n",
    "df.head()\n",
    "\n",
    "df['suma']=df.yes+df.no\n",
    "\n",
    "df.head()\n",
    "\n",
    "# From raw value to percentage\n",
    "totals = [i+j for i,j in zip(df['yes'], df['no'])]\n",
    "greenBars = [i / j * 100 for i,j in zip(df['yes'], totals)]\n",
    "orangeBars = [i / j * 100 for i,j in zip(df['no'], totals)]\n",
    "#blueBars = [i / j * 100 for i,j in zip(df['blueBars'], totals)]\n",
    " \n",
    "\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7,7))\n",
    "barWidth = 0.85\n",
    "names = ('Web', 'Phone', 'Email', 'Whatsapp', 'Social Network')\n",
    "# Create green Bars\n",
    "plt.bar(r, greenBars, color='#b5ffb9', edgecolor='white', width=barWidth, label='Yes')\n",
    "# Create orange Bars\n",
    "plt.bar(r, orangeBars, bottom=greenBars, color='mistyrose', edgecolor='white', width=barWidth, label='No')\n",
    "## Create blue Bars\n",
    "#plt.bar(r, blueBars, bottom=[i+j for i,j in zip(greenBars, orangeBars)], color='#a3acff', edgecolor='white', width=barWidth)\n",
    " \n",
    "# Custom x axis\n",
    "plt.xticks(r, names, rotation=30)\n",
    "plt.xlabel(\"CHANNEL\")\n",
    " \n",
    " \n",
    "# Add a legend\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing 'PRODUCTE(S)' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(dd['N_PROD_TOT'], bins= np.arange(0.5, 16.5, 1.0), rwidth=0.9, color='darkgreen')\n",
    "#np.arange(-0.5, 20.5, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dd.loc[(dd.N_PROD_PRINC==0) & (dd.N_PROD_TOT>0), 'N_PROD_OTROS'],bins=np.arange(-0.5, 20.5, 1.0), rwidth=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dd.loc[dd.N_PROD_PRINC==1, 'N_PROD_OTROS'],bins=np.arange(-0.5, 20.5, 1.0), rwidth=0.9)\n",
    "## Los que venden 1 producto principal, generalmente no venden otros (54) o venden 1-2 otros (27-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entre los que venden 2 o 3 productos principales, hay 27 que no venden otras cosas, pero 19 que sí \n",
    "## venden otros porudctos\n",
    "## aquí no está bien definido como era en pagesos..\n",
    "\n",
    "#data[data.N_PROD_PRINC==1].head()\n",
    "plt.hist(dd.loc[dd.N_PROD_PRINC>=2, 'N_PROD_OTROS'],bins=np.arange(-0.5, 20.5, 1.0), rwidth=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, (ax1, ax2)) = plt.subplots(1, 2, sharey=True, figsize=(10,8))\n",
    "#ax1.hist(df['normal'], bins=100)\n",
    "\n",
    "ax1.hist(dd[dd['hasDELIVERY']>0].N_PROD_PRINC, bins=np.arange(-0.5,5.5,1), rwidth=0.9, color='darkred')\n",
    "ax1.set_title('WITH DELIVERY', fontsize=15)\n",
    "ax1.set_xlabel('N. main prod', fontsize=13)\n",
    "\n",
    "#ax2.hist(df['random'], bins=100)\n",
    "ax2.hist(dd[dd['hasDELIVERY']==0].N_PROD_PRINC, bins=np.arange(-0.5,5.5,1), rwidth=0.9, color='orange')\n",
    "ax2.set_title('NO DELIVERY', fontsize=15)\n",
    "ax2.set_xlabel('N. main prod', fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#f = plt.figure(figsize=(10,8))\n",
    "#ax1 = f.add_subplot(121)\n",
    "#ax2 = f.add_subplot(122)\n",
    "\n",
    "(fig, (ax1, ax2)) = plt.subplots(1, 2, sharey=True, figsize=(10,8))\n",
    "#ax1.hist(df['normal'], bins=100)\n",
    "\n",
    "ax1.hist(dd[(dd['hasDELIVERY']>0) & (dd.N_PROD_TOT>0)].N_PROD_TOT, bins=np.arange(0.5, 12.5, 1), rwidth=0.9, color='darkred')\n",
    "ax1.set_title('WITH DELIVERY', fontsize=15)\n",
    "ax1.set_xlabel('N. total prod', fontsize=13)\n",
    "\n",
    "#ax2.hist(df['random'], bins=100)\n",
    "ax2.hist(dd[(dd['hasDELIVERY']==0 ) & (dd.N_PROD_TOT>0)].N_PROD_TOT, bins=np.arange(0.5, 12.5,1), rwidth=0.9, color='orange')\n",
    "ax2.set_title('NO DELIVERY', fontsize=15)\n",
    "ax2.set_xlabel('N. total prod', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#f = plt.figure(figsize=(10,8))\n",
    "#ax1 = f.add_subplot(121)\n",
    "#ax2 = f.add_subplot(122)\n",
    "\n",
    "(fig, (ax1, ax2)) = plt.subplots(1, 2, sharey=True, figsize=(10,8))\n",
    "#ax1.hist(df['normal'], bins=100)\n",
    "\n",
    "ax1.hist(dd[(dd['hasSHOP']>0) & (dd.N_PROD_TOT>0)].N_PROD_TOT, bins=np.arange(0.5, 12.5, 1), rwidth=0.9, color='darkred')\n",
    "ax1.set_title('with shop', fontsize=15)\n",
    "ax1.set_xlabel('N. total prod', fontsize=13)\n",
    "\n",
    "#ax2.hist(df['random'], bins=100)\n",
    "ax2.hist(dd[(dd['hasSHOP']==0 ) & (dd.N_PROD_TOT>0)].N_PROD_TOT, bins=np.arange(0.5, 12.5,1), rwidth=0.9, color='orange')\n",
    "ax2.set_title('no shop', fontsize=15)\n",
    "ax2.set_xlabel('N. total prod', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comarcas analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.groupby(['COMARCA']).agg({'PROJECTE': ['count']})\n",
    "\n",
    "dd.groupby('COMARCA').size()\n",
    "\n",
    "\n",
    "#dd['COMARCA_new']=dd.COMARCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.loc[dd['COMARCA']=='Al Urgell', 'COMARCA_new']='Alt Urgell'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Bages','COMARCA_new']='Bages-Moianès'\n",
    "dd.loc[dd['COMARCA']=='Moianès','COMARCA_new']='Bages-Moianès'\n",
    "dd.loc[dd['COMARCA']=='Moianes-Bages','COMARCA_new']='Bages-Moianès'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Barcelona','COMARCA_new']='Barcelonès'\n",
    "dd.loc[dd['COMARCA']=='Barcelones','COMARCA_new']='Barcelonès'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Tarragona','COMARCA_new']='Tarragonès'\n",
    "dd.loc[dd['COMARCA']=='Tarragones','COMARCA_new']='Tarragonès'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Baixa Cerdanya','COMARCA_new']='Cerdanya'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Repartim al Bages, Solsonès, Barcelonès i Berguedà','COMARCA_new']='Bages'\n",
    "dd.loc[dd['COMARCA']=='Maresme-Barcelonès','COMARCA_new']='Maresme'\n",
    "\n",
    "dd.loc[dd['COMARCA']=='Baix Montseny','COMARCA_new']='Vallès Oriental'\n",
    " \n",
    "#?Baixa Cerdanya    \n",
    "#?Baix Montseny                                          \n",
    "#?Repartim al Bages, Solsonès, Barcelonès i Berguedà     1\n",
    "#?Maresme-Barcelonès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.groupby(['COMARCA_new']).agg({'PROJECTE': ['count']})\n",
    "\n",
    "\n",
    "dd.groupby(['COMARCA_new'])['URGENT'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False) \n",
    "\n",
    "#dd.groupby('COMARCA_new').size()\n",
    "\n",
    "\n",
    "#dd.URGENT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
