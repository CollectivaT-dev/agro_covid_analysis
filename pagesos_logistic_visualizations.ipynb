{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afab/timeoverflow/env/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path # reads paths in the current OS\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import utils as ut\n",
    "from ipysankeywidget import SankeyWidget\n",
    "import floweaver as fw\n",
    "from floweaver import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('conf') / 'paths.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    "\n",
    "data = pd.read_csv(Path(config['input_path']) / \"all_data.csv\", sep=\",\").fillna('')\n",
    "\n",
    "locations_df = pd.read_csv(Path(config['input_path']) /  'municipis_merge.csv').fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_subset=False ##(must be set when running the script)\n",
    "#To create the sankey diagram only for a subset of producer set the parameter specific_subset=True \n",
    "# and define below the fields which must necessarily be present (i.e. >0): on_fields\n",
    "# and those which must be absent (i.e. =0): off_fields\n",
    "# as well as the label which will appear in the name of the png file\n",
    "\n",
    "if specific_subset:\n",
    "    on_fields=list(['n_main_prod']) ## must be set when running the script, if specific_subset=True\n",
    "    off_fields=list(['n_other_prod']) ## must be set when running the script, if specific_subset=True\n",
    "    label='onlyMainProd' ## must be set when running the script, if specific_subset=True\n",
    "    print('The sankey diagram will be produced considering only a subset of the whole dataset.')\n",
    "    print('Especifically, considering just those producers who do sell: ', on_fields)\n",
    "    if len(off_fields)>0:\n",
    "        print('and do not sell: ', off_fields)\n",
    "else:\n",
    "    label='all'\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if specific_subset:\n",
    "\n",
    "    if len(off_fields)>0:\n",
    "        n_flags_on=len(on_fields) \n",
    "        n_flags_off=len(off_fields)\n",
    "        \n",
    "        for i in range(0,n_flags_on):\n",
    "            df_flag = pd.DataFrame()\n",
    "            col=on_fields[i]\n",
    "            df_flag['flag_on_'+str(i)]=np.where(data[col].gt(0), 1, 0)\n",
    "            data=pd.concat([data, df_flag], axis=1)\n",
    "       \n",
    "        for i in range(0,n_flags_off):\n",
    "            df_flag = pd.DataFrame()\n",
    "            col=off_fields[i]\n",
    "            df_flag['flag_off_'+str(i)]=np.where(data[col].eq(0), 1, 0)\n",
    "            data=pd.concat([data, df_flag], axis=1)\n",
    "    \n",
    "        col_list=list()\n",
    "        for j in range(0,n_flags_on):\n",
    "            flag_col='flag_on_'+str(j)\n",
    "            col_list.append(flag_col)  \n",
    "        for j in range(0,n_flags_off):\n",
    "            flag_col='flag_off_'+str(j)\n",
    "            col_list.append(flag_col)\n",
    "            \n",
    "        data['final_flag']=np.where(data[col_list].sum(axis=1)==n_flags_on+n_flags_off, 1, 0)  ## & np.where(data[col_off_list].sum(axis=1)==n_flags_off, 1, 0)\n",
    "\n",
    "    else:\n",
    "        n_flags_on=len(on_fields) \n",
    "        #print('N fields which must be on: ', n_flags_on)\n",
    "        for i in range(0,n_flags_on):\n",
    "            df_flag = pd.DataFrame()\n",
    "            col=on_fields[i]\n",
    "            df_flag['flag_'+str(i)]=np.where(data[col].gt(0), 1, 0)\n",
    "            data=pd.concat([data, df_flag], axis=1)\n",
    "        col_list=list()\n",
    "        for j in range(0,n_flags_on):\n",
    "            flag_col='flag_'+str(j)\n",
    "            col_list.append(flag_col)\n",
    "        #print(col_list)\n",
    "        data['final_flag']=np.where(data[col_list].sum(axis=1)==n_flags_on, 1, 0)\n",
    "else:\n",
    "    data['final_flag']=1\n",
    "\n",
    "\n",
    "\n",
    "#data.tail()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections between comarcas\n",
    "Creating the dataframe needed for sankey diagram (i.e. the list of all the edges between two comarcas),\n",
    "it will have the following columns: source, target, value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting only the desired subset of producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the subset:  (541, 36)\n"
     ]
    }
   ],
   "source": [
    "data_sel=data[(data.final_flag==1) & (~data.comarca_origin.str.contains('NOTFOUND'))]\n",
    "\n",
    "print('Dimension of the subset: ', data_sel.shape)\n",
    "\n",
    "##print(data.shape)\n",
    "##data.drop(data[data.flag == 0].index, inplace=True)\n",
    "##print(data[data.flag==1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting all the target comarcas from the field 'DONDE' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]\n",
    "\n",
    "for j in range(0,data_sel.shape[0]):\n",
    "\n",
    "    targets=data_sel.DONDE.iloc[j].split(\", \")\n",
    "    n_targets=len(targets)\n",
    "    \n",
    "    if(n_targets>=40):\n",
    "        df.append((data_sel.comarca_origin.iloc[j], 'Catalunya', 1))\n",
    "    else:\n",
    "        for i in range(0,n_targets):\n",
    "            df.append((data_sel.comarca_origin.iloc[j], targets[i], 1))\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(df, columns=('source', 'target', 'value'))\n",
    "\n",
    "\n",
    "## Removing records which have no info in the target or in the source field\n",
    "df=df[~(df.target=='')]\n",
    "df=df[~(df.source=='')]\n",
    "\n",
    "\n",
    "## Uniformizing names of comarcas between the pagesos dataset and the cataloninan comarcas dataset (comarcas_df)\n",
    "standard_names = {'Osona / Lluçanès':'Osona', 'Ribera d’Ebre': 'Ribera d\\'Ebre', \n",
    "                  'Pla de l’Estany':'Pla de l\\'Estany', 'Pla d’Urgell': 'Pla d\\'Urgell'}\n",
    "df['target'] = df['target'].replace(standard_names)\n",
    "df['source'] = df['source'].replace(standard_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the final df by grouping by (source, target) couples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the normalization factor (i.e. the total number of connections per comarca of origin)  \n",
    "df_norm=df.groupby(['source'])['value'] \\\n",
    "                             .sum() \\\n",
    "                             .reset_index(name='norm_factor') \n",
    "\n",
    "\n",
    "## Grouping by the connections with same source-target: \n",
    "df_edges=df.groupby(['source', 'target'])['value'] \\\n",
    "                             .sum() \\\n",
    "                             .reset_index(name='value') \\\n",
    "                             .sort_values(['value'], ascending=False) \\\n",
    "\n",
    "\n",
    "\n",
    "## Adding the normalized factor to the edges df:\n",
    "df_edges=pd.merge(df_edges, df_norm, how='inner', left_on='source', right_on='source')\n",
    "df_edges['norm_value']=df_edges['value'].astype(float)/df_edges['norm_factor'].astype(float)*100\n",
    "\n",
    "\n",
    "#print(df_edges.head())\n",
    "#print(df_edges.shape)\n",
    "#df_edges.sort_values(by=['value'], ascending=False).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900bd23b4459448da66b965ec3024116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(groups=[{'id': 'Comarcas_productoras', 'type': 'process', 'title': '', 'nodes': ['Comarcas_produc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###https://github.com/psychemedia/parlihacks/blob/master/notebooks/MigrantFlow.ipynb)\n",
    "\n",
    "flows=df_edges[['source', 'target', 'value']]\n",
    "\n",
    "SankeyWidget(links=flows.to_dict('records'))\n",
    "\n",
    "size = dict(width=870, height=1000)\n",
    "\n",
    "nodes = {\n",
    "    'Comarcas_productoras': ProcessGroup(list(locations_df.Comarca.unique())),\n",
    "    'Comarcas_entrega': ProcessGroup(list(locations_df.Comarca.unique())),\n",
    "}\n",
    "\n",
    "ordering = [\n",
    "    ['Comarcas_productoras'],       # put \"Comarcas_productoras\" on the left...\n",
    "    ['Comarcas_entrega'],   # ... and \"Comarcas_entrega\" on the right.\n",
    "]\n",
    "\n",
    "bundles = [\n",
    "    Bundle('Comarcas_productoras', 'Comarcas_entrega'),\n",
    "]\n",
    "\n",
    "\n",
    "#sdd = SankeyDefinition(nodesA, bundles, ordering)\n",
    "#weave(sdd, flows).to_widget(**size)\n",
    "\n",
    "\n",
    "comarcas_out = Partition.Simple('process',list(locations_df.Comarca.unique()))\n",
    "comarcas_in = Partition.Simple('process',list(locations_df.Comarca.unique()))\n",
    "\n",
    "\n",
    "# Update the ProcessGroup nodes to use the partitions\n",
    "nodes['Comarcas_productoras'].partition = comarcas_out\n",
    "nodes['Comarcas_entrega'].partition = comarcas_in\n",
    "\n",
    "\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "## New Sankey!\n",
    "#weave(sdd, flows).to_widget(**size) \n",
    "\n",
    "## Saving the plot as png\n",
    "weave(sdd, flows, link_color=QuantitativeScale('value'), \\\n",
    "      measures='value').to_widget(**size).auto_save_png('SankeyDiag_2datasets_'+label+'.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
