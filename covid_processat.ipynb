{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # reads paths in the current OS\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "import utils as ut\n",
    "from stop_words import get_stop_words\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paths.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    "\n",
    "data         = pd.read_csv(Path(config['input_path']) / \"abastiment.csv\", sep=\",\").fillna('')\n",
    "locations_df = pd.read_csv(Path(config['input_path']) /  'municipis_merge.csv').fillna('')\n",
    "\n",
    "with open('com_comprar_kw.yaml') as file:\n",
    "    com_comprar = yaml.full_load(file)\n",
    "with open('product_list.yaml') as file:\n",
    "    product_cat = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a set of stop words\n",
    "stopwords = get_stop_words('catalan')\n",
    "#add new stopwords\n",
    "newStopWords = ['que','des', 'al', 'del', 'ho', 'd', 'l','per','tambe', 'fins',\n",
    "               'a', 'cap', 'hi', 'ni', 'no']\n",
    "stopwords.extend(newStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_patt = ['repart', 'domicil', 'envi', 'recoll', 'dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comarca_new is necessary because it contains some \"repartim a...\" text\n",
    "cols_to_extract_locs = ['COM COMPRAR', 'OBSERVACIONS', 'comarca_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_typos = {\n",
    "    'Al Urgell':'Alt Urgell',\n",
    "    'Bages-Moianès':'Moianès',\n",
    "    'Moianes-Bages':'Moianès',\n",
    "    'Barcelona':'Barcelonès',\n",
    "    'Maresme-Barcelonès':'Maresme',\n",
    "    'Tarragona':'Tarragonès',\n",
    "    'Baix Montseny':'Vallès Oriental',\n",
    "    'Baixa Cerdanya':'Cerdanya',\n",
    "    'Vall Aran':\"Vall d'Aran\",\n",
    "    'Alt Maresme':'Maresme',\n",
    "    'Penedès':'Alt Penedès',\n",
    "    'Lluçanès':'Osona', #should we consider it a comarca?\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comarca_new'] = data['COMARCA'].replace(com_typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comarca_new'] = data['comarca_new'].apply(lambda x: ut.check_comarca_spelling(\n",
    "    x,locations_df['Comarca'],stopwords) if x not in locations_df['Comarca'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the field 'comarca_origin': a clean version of 'COMARCA'\n",
    "data=pd.merge(data,locations_df[['Municipi', 'Comarca']], how='left', left_on='MUNICIPI', right_on='Municipi')\n",
    "\n",
    "data['comarca_origin']=data.comarca_new\n",
    "data.loc[data.comarca_origin.str.contains('NOTFOUND'), 'comarca_origin']=data.Comarca\n",
    "data.drop(['Municipi', 'Comarca'],axis=1,inplace=True)\n",
    "\n",
    "##TODO: improve this part using the dict municipio to comarca..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data.COMARCA=='Repartim al Bages, Solsonès, Barcelonès i Berguedà'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_extract_locs+['PRODUCTE(S)']:\n",
    "    data[col+'_prep'] = data[col].apply(lambda x: ut.pre_process(x, stopwords,sw=True))\n",
    "\n",
    "for col in ['Municipi', 'Comarca', 'Capital', 'Provincia']:\n",
    "    locations_df[col+'_prep'] = locations_df[col].apply(lambda x: ut.pre_process(x, stopwords,sw=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_field in cols_to_extract_locs:\n",
    "    for loc in ['Comarca','Capital','Provincia','Municipi']:\n",
    "        # obtain the locations from the free text fields\n",
    "        ut.get_text_locations(data, loc.lower(),data_field,locations_df,loc,delivery_patt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to translate municipis to comarca\n",
    "mun_to_com_dict = locations_df[locations_df['Municipi']!=''].set_index('Municipi')['Comarca'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['capital','municipi']] = data[['capital','municipi']].replace(mun_to_com_dict,regex=True)\n",
    "data['all_comarques']        = (data['capital']+','+data['municipi']+','+data['comarca']\n",
    "                               ).str.strip(',').str.split(',')\n",
    "data.drop(['capital','municipi', 'comarca_new_prep','comarca_new','comarca'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all_comarques'] = data['all_comarques'].apply(lambda x: ','.join(set(x)))\n",
    "data['all_comarques'] = data['all_comarques'].str.replace(r'\\bCatalunya\\b','Tota Catalunya')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of delivery regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variable about number of comarcas where they deliver:\n",
    "data['n_comarcas_delivery']=data['all_comarques'].apply(lambda x: x.count(',')+1 if 'Catalunya' not in x else 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variables representing whether they have a type of product (1) or not\n",
    "for key, val in product_cat.items():\n",
    "    data[key]=0\n",
    "    data.loc[data['PRODUCTE(S)'+'_prep'].str.contains(r'\\b'+r'\\b|\\b'.join(val)+r'\\b'),key] = 1\n",
    "    \n",
    "# create binary variables representing whether they have a type payment method, contact info... (1) or not\n",
    "for key, val in com_comprar.items():\n",
    "    data[key]=0\n",
    "    data.loc[data['COM COMPRAR'+'_prep'].str.contains(r'\\b'+r'\\b|\\b'.join(val)+r'\\b'),key] = 1\n",
    "# improve the website and social network searches adding another column\n",
    "data.loc[(data['web']!=1) & (data['OBSERVACIONS'+'_prep'].str.contains(\n",
    "    r'\\b'+r'\\b|\\b'.join(com_comprar['web'])+r'\\b')),'web'] = 1\n",
    "data.loc[(data['socialnet']!=1) & (data['OBSERVACIONS'+'_prep'].str.contains(\n",
    "    r'\\b'+r'\\b|\\b'.join(com_comprar['socialnet'])+r'\\b')),'socialnet'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of type of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variables about number of products sold:\n",
    "data['n_main_prod'] = data['meat'] + data['fruit'] + data['vegetables']\n",
    "data['n_other_prod'] = data['flowers'] + data['charcuterie'] + data['legumes'] + data['mushrooms'] + data['rice'] +\\\n",
    "    data['flour_cereals'] + data['oil_olives_vinager'] + data['eggs'] + data['dairies'] +\\\n",
    "    data['herbs_spices'] + data['hygiene_medicines'] + data['alcohol'] +\\\n",
    "    data['fruit_veggies_products'] + data['drinks'] + data['bread_pastries'] +\\\n",
    "    data['pasta'] + data['others']\n",
    "data['n_tot_prod'] = data['n_main_prod'] + data['n_other_prod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['PRODUCTE(S)_prep','OBSERVACIONS_prep','COM COMPRAR_prep'],axis=1\n",
    "         ).to_csv(Path(config['input_path']) / 'abastiment_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
